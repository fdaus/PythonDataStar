{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://thecads.org/wp-content/uploads/2017/02/adax_logo.jpg)\n",
    "# Module 4: Data Manipulation and Analysis with Pandas\n",
    "\n",
    "![](http://pandas.pydata.org/_static/pandas_logo.png)\n",
    "[Pandas](http://pandas.pydata.org/) is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. Pandas is free software released under the three-clause BSD license. The name is derived from the term _panel data_, an econometrics term for multidimensional structured data sets.\n",
    "\n",
    "#### Contents\n",
    "\n",
    "* [Series](#Series)\n",
    "* [DataFrames](#DataFrames)\n",
    "* [Importing Pandas](#Importing-Pandas) and other libraries.\n",
    "* [Creating Data](#Creating-Data) using lists and tuples\n",
    "* [Viewing Data](#Viewing-Data)\n",
    "* [Saving Data](#Saving-Data) to_csv and to_excel\n",
    "* [Loading Data](#Loading-Data) read_csv, read_table read_excel, read_html\n",
    "    * [Unix and os](#Unix-and-os)\n",
    "    * [CSVs and Excel](#CSVs-and-Excel)\n",
    "* [Selecting Data](#Selecting-Data) loc,iloc,isin\n",
    "    * [Masks](#Masks) or boolean arrays\n",
    "* [Preparing Data](#Preparing-Data)\n",
    "    * [Missing Values](#Missing-Values)\n",
    "    \n",
    "*[to be continued in part 4b]*\n",
    "\n",
    "NB: This notebook misses some methods of joining and concatenating and merging data. The instances in which those are useful are quite specific, so we'll see some examples but won't have a section in this notebook for reference. \n",
    "\n",
    "#### Resources:  \n",
    "* [Pandas Documentation](http://pandas.pydata.org/pandas-docs/stable/index.html), especially\n",
    "[10 minutes to pandas](http://pandas.pydata.org/pandas-docs/stable/10min.html)  \n",
    "* [The Data Incubator](https://www.thedataincubator.com/)  \n",
    "* [Hernan Rojas' learn-pandas](https://bitbucket.org/hrojas/learn-pandas)  \n",
    "* [Harvard CS109 lab1 content](https://github.com/cs109/2015lab1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pandas library as pd\n",
    "import pandas as pd\n",
    "#import matplotlib library as plt \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2    Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a pandas series from list\n",
    "#observe the dtype\n",
    "animals = ['Tiger', 'Bear', 'Moose']\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a pandas series from list\n",
    "#observe the dtype\n",
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Tiger\n",
       "1     Bear\n",
       "2     None\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it is possible to create a pandas series with None, indicating no data\n",
    "#observe the dtype\n",
    "animals = ['Tiger', 'Bear', None]\n",
    "pd.Series(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in the case of numbers, None will give a NaN (Not a Number)\n",
    "#observe the dtype\n",
    "numbers = [1, 2, None]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a pandas series from dictionary\n",
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what's the type for s?\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Archery', 'Golf', 'Sumo', 'Taekwondo'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notice the index for s\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India      Tiger\n",
       "America     Bear\n",
       "Canada     Moose\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can also create a series from list and index\n",
    "sr = pd.Series(['Tiger', 'Bear', 'Moose'], index=['India', 'America', 'Canada'])\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Golf      Scotland\n",
       "Sumo         Japan\n",
       "Hockey         NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a list can be created based on the specified indices\n",
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "sp1 = pd.Series(sports, index=['Golf', 'Sumo', 'Hockey'])\n",
    "sp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports = {'Archery': 'Bhutan',\n",
    "          'Golf': 'Scotland',\n",
    "          'Sumo': 'Japan',\n",
    "          'Taekwondo': 'South Korea'}\n",
    "s = pd.Series(sports)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iloc to query based on index\n",
    "s.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scotland'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loc to query based on location\n",
    "s.loc['Golf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Korea'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to query based on index\n",
    "s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scotland'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to query based on location\n",
    "s['Golf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sports = {99: 'Bhutan',\n",
    "          100: 'Scotland',\n",
    "          101: 'Japan',\n",
    "          102: 'South Korea'}\n",
    "s = pd.Series(sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bhutan'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.iloc[0] #This won't call s.iloc[0] as one might expect, it generates an error instead\n",
    "\n",
    "# try s[99] or s[101]. What can you make of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a pandas series from a dictionary and a list -- flexible!\n",
    "original_sports = pd.Series({'Archery': 'Bhutan',\n",
    "                             'Golf': 'Scotland',\n",
    "                             'Sumo': 'Japan',\n",
    "                             'Taekwondo': 'South Korea'})\n",
    "\n",
    "cricket_loving_countries = pd.Series(['Australia',\n",
    "                                      'Barbados',\n",
    "                                      'Pakistan',\n",
    "                                      'England'], \n",
    "                                index=['Cricket',\n",
    "                                       'Cricket',\n",
    "                                       'Cricket',\n",
    "                                       'Cricket'])\n",
    "all_countries = original_sports.append(cricket_loving_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archery           Bhutan\n",
       "Golf            Scotland\n",
       "Sumo               Japan\n",
       "Taekwondo    South Korea\n",
       "Cricket        Australia\n",
       "Cricket         Barbados\n",
       "Cricket         Pakistan\n",
       "Cricket          England\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cricket    Australia\n",
       "Cricket     Barbados\n",
       "Cricket     Pakistan\n",
       "Cricket      England\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using loc to list all countries with the index 'Cricket'\n",
    "all_countries.loc['Cricket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "\n",
    "A data frame is like a table, with rows and columns (e.g., as in SQL or Excel).  \n",
    "**Except** that :\n",
    "  - The rows can be indexed by something interesting (there is special support for labels like categorical and timeseries data).\n",
    "  - Cells can store any Python object. Like in SQL, columns must have a homogenous type.\n",
    "  - Instead of \"NULL\", the name for a non-existent value is \"NA\".  Unlike R, Python's data frames only support NAs in columns of some data types (basically: floating point numbers and 'objects') -- but this is mostly a non-issue (because it will \"up-type\" integers to float64, etc.)\n",
    "  \n",
    "Each of a ```DataFrame```'s columns are an individual ```Series```, (more correctly, a dataframe is a dictionary of Series).  The entires series must have a homogenous type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example 1\n",
    "# Let's make a dataset that consists of Malaysian States\n",
    "# and the size of each state in km2.  Let's try and rank \n",
    "# the states of Malaysia by land area, and figure out if East\n",
    "# Malaysia is larger or smaller than West Malaysia\n",
    "\n",
    "states = ['Johor','Kedah','Kelantan','Melaka', \n",
    "          'Negeri Sembilan','Pahang','Perak','Perlis',\n",
    "          'Penang','Sabah', 'Sarawak','Selangor','Terengganu']\n",
    "area = [19210,9500,15099,1664,6686,36137,21035,\n",
    "        821,1048,73631,124450,8104,13035]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the zip function to merge the two lists together\n",
    "zip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Johor', 19210),\n",
       " ('Kedah', 9500),\n",
       " ('Kelantan', 15099),\n",
       " ('Melaka', 1664),\n",
       " ('Negeri Sembilan', 6686),\n",
       " ('Pahang', 36137),\n",
       " ('Perak', 21035),\n",
       " ('Perlis', 821),\n",
       " ('Penang', 1048),\n",
       " ('Sabah', 73631),\n",
       " ('Sarawak', 124450),\n",
       " ('Selangor', 8104),\n",
       " ('Terengganu', 13035)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area Data Set\n",
    "state_area = list(zip(states, area))\n",
    "state_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now will use the ***pandas*** library to export this data set into a csv file. \n",
    "\n",
    "***df*** will be a ***DataFrame*** object. You can think of this object holding the contents of states in a format similar to a sql table or an excel spreadsheet. Let's take a look below at the contents inside ***df***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johor</td>\n",
       "      <td>19210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kedah</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kelantan</td>\n",
       "      <td>15099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melaka</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negeri Sembilan</td>\n",
       "      <td>6686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State   Area\n",
       "0            Johor  19210\n",
       "1            Kedah   9500\n",
       "2         Kelantan  15099\n",
       "3           Melaka   1664\n",
       "4  Negeri Sembilan   6686"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = state_area, columns=['State', 'Area'])\n",
    "#head to show first 5 rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 2 columns):\n",
      "State    13 non-null object\n",
      "Area     13 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 288.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print((type(df)))\n",
    "print() \n",
    "print((df.info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25416.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35627.125329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>821.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6686.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>124450.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Area\n",
       "count      13.000000\n",
       "mean    25416.923077\n",
       "std     35627.125329\n",
       "min       821.000000\n",
       "25%      6686.000000\n",
       "50%     13035.000000\n",
       "75%     21035.000000\n",
       "max    124450.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#provide statistical summary for the whole dataset\n",
    "df.describe()\n",
    "#find out what these statistics are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sarawak</td>\n",
       "      <td>124450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sabah</td>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pahang</td>\n",
       "      <td>36137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perak</td>\n",
       "      <td>21035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johor</td>\n",
       "      <td>19210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kelantan</td>\n",
       "      <td>15099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Terengganu</td>\n",
       "      <td>13035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kedah</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Selangor</td>\n",
       "      <td>8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negeri Sembilan</td>\n",
       "      <td>6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melaka</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Penang</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perlis</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              State    Area\n",
       "10          Sarawak  124450\n",
       "9             Sabah   73631\n",
       "5            Pahang   36137\n",
       "6             Perak   21035\n",
       "0             Johor   19210\n",
       "2          Kelantan   15099\n",
       "12       Terengganu   13035\n",
       "1             Kedah    9500\n",
       "11         Selangor    8104\n",
       "4   Negeri Sembilan    6686\n",
       "3            Melaka    1664\n",
       "8            Penang    1048\n",
       "7            Perlis     821"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Area']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sarawak</td>\n",
       "      <td>124450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sabah</td>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pahang</td>\n",
       "      <td>36137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perak</td>\n",
       "      <td>21035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johor</td>\n",
       "      <td>19210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State    Area\n",
       "10  Sarawak  124450\n",
       "9     Sabah   73631\n",
       "5    Pahang   36137\n",
       "6     Perak   21035\n",
       "0     Johor   19210"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking of land area -- top 5\n",
    "# East Malaysia looks big!\n",
    "df = df.sort_values('Area', ascending=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sabah</th>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sarawak</th>\n",
       "      <td>124450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Area\n",
       "Sabah     73631\n",
       "Sarawak  124450"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stateDF['State'][:2]\n",
    "#stateDF[stateDF['State'] == 'Sarawak']\n",
    "sdf = pd.Series(area, index = states)\n",
    "#print(sdf)\n",
    "sdf = pd.DataFrame(sdf, columns=['Area'])\n",
    "#print(sdf)\n",
    "sdf.filter(items =['Sabah','Sarawak'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sabah</td>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sarawak</td>\n",
       "      <td>124450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State    Area\n",
       "9     Sabah   73631\n",
       "10  Sarawak  124450"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateDF = df\n",
    "stateDF.filter(items =[9,10],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('East Malaysia Size: ', 198081)\n",
      "('West Malaysia Size: ', 132339)\n"
     ]
    }
   ],
   "source": [
    "# Excluding WPs, East Malaysia is larger than West Malaysia!\n",
    "print(('East Malaysia Size: ', df['Area'][0:2].sum()))           # get only data from row 9 and 10 to be summed\n",
    "print(('West Malaysia Size: ', df['Area'].sum() - df['Area'][0:2].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAFfCAYAAACRCsEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1824234d748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create graph\n",
    "df['Area'].plot.bar()\n",
    "plt.xticks(np.arange(13), (df['State']))\n",
    "plt.xlabel('Malaysian States')\n",
    "plt.ylabel('Land Area in $km^2$')\n",
    "plt.title('Malaysian States by Land Area')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# before we proceed to the second example, let's store the DataFrame 'df' in another variable\n",
    "stateDF = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>22.5</td>\n",
       "      <td>Dog Food</td>\n",
       "      <td>Chris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>Kitty Litter</td>\n",
       "      <td>Kevyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bird Seed</td>\n",
       "      <td>Vinod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cost Item Purchased   Name\n",
       "Store 1  22.5       Dog Food  Chris\n",
       "Store 1   2.5   Kitty Litter  Kevyn\n",
       "Store 2   5.0      Bird Seed  Vinod"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 2\n",
    "purchase_1 = pd.Series({'Name': 'Chris',\n",
    "                        'Item Purchased': 'Dog Food',\n",
    "                        'Cost': 22.50})\n",
    "purchase_2 = pd.Series({'Name': 'Kevyn',\n",
    "                        'Item Purchased': 'Kitty Litter',\n",
    "                        'Cost': 2.50})\n",
    "purchase_3 = pd.Series({'Name': 'Vinod',\n",
    "                        'Item Purchased': 'Bird Seed',\n",
    "                        'Cost': 5.00})\n",
    "df = pd.DataFrame([purchase_1, purchase_2, purchase_3], index=['Store 1', 'Store 1', 'Store 2'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cost                      5\n",
       "Item Purchased    Bird Seed\n",
       "Name                  Vinod\n",
       "Name: Store 2, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Store 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc['Store 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>22.5</td>\n",
       "      <td>Dog Food</td>\n",
       "      <td>Chris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>Kitty Litter</td>\n",
       "      <td>Kevyn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cost Item Purchased   Name\n",
       "Store 1  22.5       Dog Food  Chris\n",
       "Store 1   2.5   Kitty Litter  Kevyn"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Store 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store 1    22.5\n",
       "Store 1     2.5\n",
       "Name: Cost, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Store 1', 'Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store 1</th>\n",
       "      <th>Store 1</th>\n",
       "      <th>Store 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cost</th>\n",
       "      <td>22.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item Purchased</th>\n",
       "      <td>Dog Food</td>\n",
       "      <td>Kitty Litter</td>\n",
       "      <td>Bird Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Kevyn</td>\n",
       "      <td>Vinod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Store 1       Store 1    Store 2\n",
       "Cost                22.5           2.5          5\n",
       "Item Purchased  Dog Food  Kitty Litter  Bird Seed\n",
       "Name               Chris         Kevyn      Vinod"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transpose dataframe\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store 1    22.5\n",
       "Store 1     2.5\n",
       "Store 2       5\n",
       "Name: Cost, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.loc['Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store 1    22.5\n",
       "Store 1     2.5\n",
       "Store 2     5.0\n",
       "Name: Cost, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store 1    22.5\n",
       "Store 1     2.5\n",
       "Name: Cost, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Store 1']['Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>Chris</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>Kevyn</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 2</th>\n",
       "      <td>Vinod</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Cost\n",
       "Store 1  Chris  22.5\n",
       "Store 1  Kevyn   2.5\n",
       "Store 2  Vinod   5.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['Name', 'Cost']]\n",
    "#df.T.loc['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bird Seed</td>\n",
       "      <td>Vinod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cost Item Purchased   Name\n",
       "Store 2   5.0      Bird Seed  Vinod"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to delete a row\n",
    "df.drop('Store 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>22.5</td>\n",
       "      <td>Dog Food</td>\n",
       "      <td>Chris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>Kitty Litter</td>\n",
       "      <td>Kevyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bird Seed</td>\n",
       "      <td>Vinod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cost Item Purchased   Name\n",
       "Store 1  22.5       Dog Food  Chris\n",
       "Store 1   2.5   Kitty Litter  Kevyn\n",
       "Store 2   5.0      Bird Seed  Vinod"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notice that drop does not change the original dataset\n",
    "#drop created a copy instead\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bird Seed</td>\n",
       "      <td>Vinod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cost Item Purchased   Name\n",
       "Store 2   5.0      Bird Seed  Vinod"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df = df.copy()\n",
    "copy_df = copy_df.drop('Store 1')\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Item Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bird Seed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cost Item Purchased\n",
       "Store 2   5.0      Bird Seed"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use del\n",
    "#will change the original dataset\n",
    "del copy_df['Name']\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cost</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>22.5</td>\n",
       "      <td>Dog Food</td>\n",
       "      <td>Chris</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>Kitty Litter</td>\n",
       "      <td>Kevyn</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store 2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bird Seed</td>\n",
       "      <td>Vinod</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cost Item Purchased   Name Location\n",
       "Store 1  22.5       Dog Food  Chris     None\n",
       "Store 1   2.5   Kitty Litter  Kevyn     None\n",
       "Store 2   5.0      Bird Seed  Vinod     None"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a new column 'Location' with None value\n",
    "df['Location'] = None\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Pandas\n",
    "\n",
    "The general way to import libraries is to write\n",
    "```python\n",
    "import library #import the library directly\n",
    "import library as alias \n",
    "\n",
    "# This just aliases the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "\n",
    "from library import function # import specific functions or types in a library\n",
    "%jupyter magic # jupyter only functions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some imports - for style reasons, try and put in alphabetical order, unless there are subgroupings of imports\n",
    "# that you want.\n",
    "import matplotlib #we'll only use this to determine the matplotlib version number\n",
    "import matplotlib.pyplot as plt  # the graphing library\n",
    "import numpy as np # scientific computing library\n",
    "import pandas as pd # the data structure and analysis library\n",
    "from pandas import DataFrame, read_csv, Series # specific functions from pandas\n",
    "import seaborn as sns # Makes graphs look pretty\n",
    "import sys #we'll only use this to determine the python version number\n",
    "\n",
    "# Enable inline plotting.  The % is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                   Type         Data/Info\n",
      "-------------------------------------------------\n",
      "a                          zip          <zip object at 0x000001824233BD48>\n",
      "all_countries              Series       Archery           Bhutan\\<...>   England\\ndtype: object\n",
      "animals                    list         n=3\n",
      "area                       list         n=13\n",
      "copy_df                    DataFrame             Cost Item Purcha<...>re 2   5.0      Bird Seed\n",
      "cricket_loving_countries   Series       Cricket    Australia\\nCri<...>   England\\ndtype: object\n",
      "df                         DataFrame             Cost Item Purcha<...>Bird Seed  Vinod     None\n",
      "np                         module       <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "numbers                    list         n=3\n",
      "original_sports            Series       Archery           Bhutan\\<...>outh Korea\\ndtype: object\n",
      "pd                         module       <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plt                        module       <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "purchase_1                 Series       Cost                  22.<...>     Chris\\ndtype: object\n",
      "purchase_2                 Series       Cost                     <...>     Kevyn\\ndtype: object\n",
      "purchase_3                 Series       Cost                     <...>     Vinod\\ndtype: object\n",
      "s                          Series       99          Bhutan\\n100  <...>outh Korea\\ndtype: object\n",
      "sp1                        Series       Golf      Scotland\\nSumo <...>       NaN\\ndtype: object\n",
      "sports                     dict         n=4\n",
      "sr                         Series       India      Tiger\\nAmerica<...>     Moose\\ndtype: object\n",
      "stateDF                    DataFrame                  State    Ar<...>           Perlis     821\n",
      "state_area                 list         n=13\n",
      "states                     list         n=13\n"
     ]
    }
   ],
   "source": [
    "# All the imports are listed as modules, including pyplot.  But there are several other types\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.0 |Anaconda custom (64-bit)| (default, Dec 23 2016, 11:57:41) [MSC v.1900 64 bit (AMD64)]\n",
      "\n",
      "Pandas version: 0.19.2\n",
      "Matplotlib version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# How to check your version numbers\n",
    "print(('Python version: ' + sys.version))\n",
    "print() \n",
    "print(('Pandas version: ' + pd.__version__))\n",
    "print(('Matplotlib version: ' + matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data\n",
    "\n",
    "There are many ways to input data into Pandas. The goal of this is to input data to DataFrames.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  animal  number\n",
      "0    cat       1\n",
      "1    dog       2\n",
      "2  mouse       3\n",
      "  animal  number\n",
      "0    cat       1\n",
      "1    dog       2\n",
      "2  mouse       3\n"
     ]
    }
   ],
   "source": [
    "# A data frame, using a dictionary with ordered \n",
    "# lists for columns\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'number': [1, 2, 3],\n",
    "    'animal': ['cat', 'dog', 'mouse']\n",
    "})\n",
    "\n",
    "# The same data frame, using tuples for each row\n",
    "# We need to give the column names separately!\n",
    "df2 = pd.DataFrame([\n",
    "    ('cat', 1),\n",
    "    ('dog', 2),\n",
    "    ('mouse', 3),\n",
    "], columns=['animal', 'number'])\n",
    "\n",
    "# Are they the same?\n",
    "assert((df1 == df2).all().all)\n",
    "print(df2)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-11-01', '2016-11-02', '2016-11-03', '2016-11-04',\n",
       "               '2016-11-05', '2016-11-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('20161101',periods =6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-01</th>\n",
       "      <td>0.169311</td>\n",
       "      <td>-0.718385</td>\n",
       "      <td>0.873104</td>\n",
       "      <td>0.760139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-02</th>\n",
       "      <td>1.754072</td>\n",
       "      <td>-0.466800</td>\n",
       "      <td>-1.227002</td>\n",
       "      <td>0.068955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-03</th>\n",
       "      <td>0.460741</td>\n",
       "      <td>-0.380639</td>\n",
       "      <td>-0.520751</td>\n",
       "      <td>-1.254284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-04</th>\n",
       "      <td>0.409966</td>\n",
       "      <td>-1.577272</td>\n",
       "      <td>1.694739</td>\n",
       "      <td>-0.343712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-05</th>\n",
       "      <td>-0.038990</td>\n",
       "      <td>0.409180</td>\n",
       "      <td>-1.510497</td>\n",
       "      <td>0.544901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-06</th>\n",
       "      <td>-0.025962</td>\n",
       "      <td>-0.782641</td>\n",
       "      <td>-0.562268</td>\n",
       "      <td>-1.161437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2016-11-01  0.169311 -0.718385  0.873104  0.760139\n",
       "2016-11-02  1.754072 -0.466800 -1.227002  0.068955\n",
       "2016-11-03  0.460741 -0.380639 -0.520751 -1.254284\n",
       "2016-11-04  0.409966 -1.577272  1.694739 -0.343712\n",
       "2016-11-05 -0.038990  0.409180 -1.510497  0.544901\n",
       "2016-11-06 -0.025962 -0.782641 -0.562268 -1.161437"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Create another DataFrame, with different data types.  \n",
    "Side note that that you can **copy** examples from the internet \n",
    "like this into Jupyter Notebook, it will still works, but only if there isn't anything else in the cell!\n",
    "\n",
    "From: http://pandas.pydata.org/pandas-docs/stable/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A          B    C  D      E    F\n",
       "0  1.0 2013-01-02  1.0  3   test  foo\n",
       "1  1.0 2013-01-02  1.0  3  train  foo\n",
       "2  1.0 2013-01-02  1.0  3   test  foo\n",
       "3  1.0 2013-01-02  1.0  3  train  foo"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [10]: df2 = pd.DataFrame({ 'A' : 1.,\n",
    "   ....:                      'B' : pd.Timestamp('20130102'),\n",
    "   ....:                      'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "   ....:                      'D' : np.array([3] * 4,dtype='int32'),\n",
    "   ....:                      'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "   ....:                      'F' : 'foo' })\n",
    "   ....: \n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! It works huh? (Even with all the extra stuff at the margin side...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A           float64\n",
       "B    datetime64[ns]\n",
       "C           float32\n",
       "D             int32\n",
       "E          category\n",
       "F            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe Columns have specific data types\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a single column, which yields a Series.\n",
    "\n",
    "A Series, like a numpy array, most be of homogenous type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      cat\n",
       "1      dog\n",
       "2    mouse\n",
       "Name: animal, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like Dictionaries! DataFrame is a dictionary of Series!\n",
    "df1['animal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      cat\n",
       "1      dog\n",
       "2    mouse\n",
       "Name: animal, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also access a column as a property of df1\n",
    "df1.animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-04</th>\n",
       "      <td>0.409966</td>\n",
       "      <td>-1.577272</td>\n",
       "      <td>1.694739</td>\n",
       "      <td>-0.343712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-05</th>\n",
       "      <td>-0.038990</td>\n",
       "      <td>0.409180</td>\n",
       "      <td>-1.510497</td>\n",
       "      <td>0.544901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2016-11-04  0.409966 -1.577272  1.694739 -0.343712\n",
       "2016-11-05 -0.038990  0.409180 -1.510497  0.544901"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can access rows like how you would with lists...\n",
    "df3[3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data\n",
    "\n",
    "#### Exporting to CSVs and Excel files\n",
    "\n",
    "Let's revive back our earlier example on the Malaysian states and export the DataFrame `df` to a ***csv*** file. We can name the file ***malaysia_states.csv***, but we can also do a txt file! The function ***to_csv*** will be used to export the file. The file will be saved in the same location of the notebook unless specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy back from stateDF (which has the Malaysian states data. There's actually no purpose in doing this but \n",
    "# just to keep the variable short :) \n",
    "df = stateDF   \n",
    "df.to_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only parameters we will use is ***index*** and ***header***. Setting these parameters to True will prevent the index and header names from being exported. Change the values of these parameters to get a better understanding of their use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('malaysia_states.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's also try a text file\n",
    "# CSV actually stands for comma separated values, which can be opened as a text file \n",
    "df.to_csv('malaysia_states.txt',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_excel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And to Excel files\n",
    "df.to_excel('malaysia_states.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Reset our namespace; delete all variables\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type         Data/Info\n",
      "---------------------------------\n",
      "df         DataFrame                      0      <...>       Terengganu   13035\n",
      "np         module       <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "path       str          malaysia_states.csv\n",
      "pd         module       <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plt        module       <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "random     module       <module 'numpy.random' fr<...>py\\\\random\\\\__init__.py'>\n",
      "sns        module       <module 'seaborn' from 'C<...>s\\\\seaborn\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import again\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy.random as random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type         Data/Info\n",
      "---------------------------------\n",
      "df         DataFrame                      0      <...>       Terengganu   13035\n",
      "np         module       <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "path       str          malaysia_states.csv\n",
      "pd         module       <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "plt        module       <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "random     module       <module 'numpy.random' fr<...>py\\\\random\\\\__init__.py'>\n",
      "sns        module       <module 'seaborn' from 'C<...>s\\\\seaborn\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Let's now try accessing that csv that we just saved.  Let us take a look at this function and what inputs it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this functions has many parameters, we will simply pass it the location of the text file. We know that we saved things into the same directory.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVs and Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Johor</th>\n",
       "      <th>19210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kedah</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kelantan</td>\n",
       "      <td>15099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melaka</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negeri Sembilan</td>\n",
       "      <td>6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pahang</td>\n",
       "      <td>36137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perak</td>\n",
       "      <td>21035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perlis</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Penang</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sabah</td>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sarawak</td>\n",
       "      <td>124450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Selangor</td>\n",
       "      <td>8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Terengganu</td>\n",
       "      <td>13035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Johor   19210\n",
       "0             Kedah    9500\n",
       "1          Kelantan   15099\n",
       "2            Melaka    1664\n",
       "3   Negeri Sembilan    6686\n",
       "4            Pahang   36137\n",
       "5             Perak   21035\n",
       "6            Perlis     821\n",
       "7            Penang    1048\n",
       "8             Sabah   73631\n",
       "9           Sarawak  124450\n",
       "10         Selangor    8104\n",
       "11       Terengganu   13035"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'malaysia_states.csv'    # why is there an 'r' in front of the filename?\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_csv` function treated the first record in the csv file as the header names. This is obviously not correct since the text file did not provide us with header names.\n",
    "To correct this we will pass the header parameter to the `read_csv` function and set it to None (means null in python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johor</td>\n",
       "      <td>19210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kedah</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kelantan</td>\n",
       "      <td>15099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melaka</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negeri Sembilan</td>\n",
       "      <td>6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pahang</td>\n",
       "      <td>36137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perak</td>\n",
       "      <td>21035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perlis</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Penang</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sabah</td>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sarawak</td>\n",
       "      <td>124450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Selangor</td>\n",
       "      <td>8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Terengganu</td>\n",
       "      <td>13035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1\n",
       "0             Johor   19210\n",
       "1             Kedah    9500\n",
       "2          Kelantan   15099\n",
       "3            Melaka    1664\n",
       "4   Negeri Sembilan    6686\n",
       "5            Pahang   36137\n",
       "6             Perak   21035\n",
       "7            Perlis     821\n",
       "8            Penang    1048\n",
       "9             Sabah   73631\n",
       "10          Sarawak  124450\n",
       "11         Selangor    8104\n",
       "12       Terengganu   13035"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path, header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to give the columns specific names, we would have to pass another parameter called `names`. We can also omit the header parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Johor</td>\n",
       "      <td>19210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kedah</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kelantan</td>\n",
       "      <td>15099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melaka</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negeri Sembilan</td>\n",
       "      <td>6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pahang</td>\n",
       "      <td>36137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perak</td>\n",
       "      <td>21035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Perlis</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Penang</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sabah</td>\n",
       "      <td>73631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sarawak</td>\n",
       "      <td>124450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Selangor</td>\n",
       "      <td>8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Terengganu</td>\n",
       "      <td>13035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              State    Area\n",
       "0             Johor   19210\n",
       "1             Kedah    9500\n",
       "2          Kelantan   15099\n",
       "3            Melaka    1664\n",
       "4   Negeri Sembilan    6686\n",
       "5            Pahang   36137\n",
       "6             Perak   21035\n",
       "7            Perlis     821\n",
       "8            Penang    1048\n",
       "9             Sabah   73631\n",
       "10          Sarawak  124450\n",
       "11         Selangor    8104\n",
       "12       Terengganu   13035"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_df = pd.read_csv(path, names=['State','Area'])\n",
    "area_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the numbers [0,1,2,3,4] as the row numbers in an Excel file. In pandas these are part of the ***index*** of the dataframe. You can think of the index as the primary key of a SQL table with the exception that an index is allowed to have duplicates.  \n",
    "\n",
    "***[State, Area]*** can be thought of as column headers similar to the ones typically found in an Excel spreadsheet or SQL database.\n",
    "\n",
    "Now, to delete the csv file now that we are done using it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using a Python Library - you can also use the unix command directly! Easy!\n",
    "import os\n",
    "os.remove(path)   # we had the filename stored in 'path' earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'malaysia_states.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-81c3db78ecbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Note that we do the same with xls files, only use read_excel.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Try it!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheetname, header, skiprows, skip_footer, index_col, names, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, has_index_names, converters, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     return io._parse_excel(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'malaysia_states.csv'"
     ]
    }
   ],
   "source": [
    "# Note that we do the same with xls files, only use read_excel.\n",
    "# Try it!\n",
    "pd.read_excel(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data\n",
    "\n",
    "We can select data both by their labels and by their position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-01-01', '2016-01-02', '2016-01-03', '2016-01-04',\n",
      "               '2016-01-05', '2016-01-06'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>-0.309560</td>\n",
       "      <td>-0.437071</td>\n",
       "      <td>0.159702</td>\n",
       "      <td>-0.988319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "      <td>1.250235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>1.336080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "      <td>0.110201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "      <td>0.280624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.613064</td>\n",
       "      <td>-0.131597</td>\n",
       "      <td>2.137900</td>\n",
       "      <td>-0.926506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2016-01-01 -0.309560 -0.437071  0.159702 -0.988319\n",
       "2016-01-02  0.135802  0.709600  0.454558  1.250235\n",
       "2016-01-03  0.700066  1.060917 -0.947943  1.336080\n",
       "2016-01-04  0.454405 -0.783037 -0.763682  0.110201\n",
       "2016-01-05  0.033045  0.046616  1.319882  0.280624\n",
       "2016-01-06 -0.613064 -0.131597  2.137900 -0.926506"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('20160101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "print(dates)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try head, tail, index, columns, values, describe, T, sort_index\n",
    "# sort_values and see for yourself what they do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-01 00:00:00\n",
      "A   -0.309560\n",
      "B   -0.437071\n",
      "C    0.159702\n",
      "D   -0.988319\n",
      "Name: 2016-01-01 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Getting a cross section on a label (or in other words, a row)\n",
    "print((dates[0]))\n",
    "print((df.loc[dates[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>-0.309560</td>\n",
       "      <td>-0.437071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.613064</td>\n",
       "      <td>-0.131597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2016-01-01 -0.309560 -0.437071\n",
       "2016-01-02  0.135802  0.709600\n",
       "2016-01-03  0.700066  1.060917\n",
       "2016-01-04  0.454405 -0.783037\n",
       "2016-01-05  0.033045  0.046616\n",
       "2016-01-06 -0.613064 -0.131597"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting on a multi-axis by label\n",
    "df.loc[:,['A','B']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   B         C\n",
       "2016-01-03  1.060917 -0.947943\n",
       "2016-01-04 -0.783037 -0.763682\n",
       "2016-01-05  0.046616  1.319882"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing label slicing, both endpoints are included unlike normal slicing\n",
    "df.loc['20160103':'20160105',['B','C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3360800538551749"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a scalar value... both work!\n",
    "df.loc[dates[2],'D']\n",
    "#df.at[dates[2],'D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```iloc``` is the same as ```loc```, only it works by position, not by label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3360800538551749"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select via the position of the passed integers\n",
    "df.iloc[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B\n",
       "2016-01-04  0.454405 -0.783037\n",
       "2016-01-05  0.033045  0.046616"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By integer slices, acting similarly to numpy/python\n",
    "df.iloc[3:5,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.454558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>-0.947943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>1.319882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         C\n",
       "2016-01-02  0.135802  0.454558\n",
       "2016-01-03  0.700066 -0.947943\n",
       "2016-01-05  0.033045  1.319882"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By lists of integer position locations, \n",
    "# similar to the numpy/python style\n",
    "df.iloc[[1,2,4],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "      <td>1.250235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>1.336080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2016-01-02  0.135802  0.709600  0.454558  1.250235\n",
       "2016-01-03  0.700066  1.060917 -0.947943  1.336080"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iloc is used to slice rows and columns explicitly\n",
    "df.iloc[1:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>-0.437071</td>\n",
       "      <td>0.159702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.131597</td>\n",
       "      <td>2.137900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   B         C\n",
       "2016-01-01 -0.437071  0.159702\n",
       "2016-01-02  0.709600  0.454558\n",
       "2016-01-03  1.060917 -0.947943\n",
       "2016-01-04 -0.783037 -0.763682\n",
       "2016-01-05  0.046616  1.319882\n",
       "2016-01-06 -0.131597  2.137900"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70959952900312206"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For getting a value explicitly\n",
    "df.iloc[1,1]\n",
    "# df.iat[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks\n",
    "\n",
    "We can use _boolean arrays_ to select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-01-01    False\n",
       "2016-01-02     True\n",
       "2016-01-03     True\n",
       "2016-01-04     True\n",
       "2016-01-05     True\n",
       "2016-01-06    False\n",
       "Freq: D, Name: A, dtype: bool"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.A>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "      <td>1.250235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>1.336080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "      <td>0.110201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "      <td>0.280624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2016-01-02  0.135802  0.709600  0.454558  1.250235\n",
       "2016-01-03  0.700066  1.060917 -0.947943  1.336080\n",
       "2016-01-04  0.454405 -0.783037 -0.763682  0.110201\n",
       "2016-01-05  0.033045  0.046616  1.319882  0.280624"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.A > 0]    # can you figure out intuitively what this does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "      <td>1.250235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.336080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "      <td>0.280624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.137900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2016-01-01       NaN       NaN  0.159702       NaN\n",
       "2016-01-02  0.135802  0.709600  0.454558  1.250235\n",
       "2016-01-03  0.700066  1.060917       NaN  1.336080\n",
       "2016-01-04  0.454405       NaN       NaN  0.110201\n",
       "2016-01-05  0.033045  0.046616  1.319882  0.280624\n",
       "2016-01-06       NaN       NaN  2.137900       NaN"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>-0.309560</td>\n",
       "      <td>-0.437071</td>\n",
       "      <td>0.159702</td>\n",
       "      <td>-0.988319</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "      <td>1.250235</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>1.336080</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "      <td>0.110201</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "      <td>0.280624</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.613064</td>\n",
       "      <td>-0.131597</td>\n",
       "      <td>2.137900</td>\n",
       "      <td>-0.926506</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D      E\n",
       "2016-01-01 -0.309560 -0.437071  0.159702 -0.988319    one\n",
       "2016-01-02  0.135802  0.709600  0.454558  1.250235    one\n",
       "2016-01-03  0.700066  1.060917 -0.947943  1.336080    two\n",
       "2016-01-04  0.454405 -0.783037 -0.763682  0.110201  three\n",
       "2016-01-05  0.033045  0.046616  1.319882  0.280624   four\n",
       "2016-01-06 -0.613064 -0.131597  2.137900 -0.926506  three"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['E'] = ['one', 'one','two','three','four','three']    # create a new column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>1.336080</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "      <td>0.280624</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D     E\n",
       "2016-01-03  0.700066  1.060917 -0.947943  1.336080   two\n",
       "2016-01-05  0.033045  0.046616  1.319882  0.280624  four"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['E'].isin(['two','four'])]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   A         B         C         D      E\n",
      "2016-01-01 -0.309560 -0.437071  0.159702 -0.988319    one\n",
      "2016-01-02  0.135802  0.709600  0.454558  1.250235    one\n",
      "2016-01-03  0.700066  1.060917 -0.947943  1.336080    two\n",
      "2016-01-04  0.454405 -0.783037 -0.763682  0.110201  three\n",
      "2016-01-05  0.033045  0.046616  1.319882  0.280624   four\n",
      "2016-01-06 -0.613064 -0.131597  2.137900 -0.926506  three\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159702</td>\n",
       "      <td>5</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "      <td>5</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>5</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "      <td>5</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "      <td>5</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.613064</td>\n",
       "      <td>-0.131597</td>\n",
       "      <td>2.137900</td>\n",
       "      <td>5</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D      E\n",
       "2016-01-01  0.000000  0.000000  0.159702  5    one\n",
       "2016-01-02  0.135802  0.709600  0.454558  5    one\n",
       "2016-01-03  0.700066  1.060917 -0.947943  5    two\n",
       "2016-01-04  0.454405 -0.783037 -0.763682  5  three\n",
       "2016-01-05  0.033045  0.046616  1.319882  5   four\n",
       "2016-01-06 -0.613064 -0.131597  2.137900  5  three"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can set data in a variety of ways\n",
    "print(df)\n",
    "df.at[dates[0],'A'] = 0               \n",
    "df.iat[0,1] = 0                       \n",
    "df.loc[:,'D'] = np.array([5] * len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159702</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>0.454558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>0.700066</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>1.319882</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.613064</td>\n",
       "      <td>-0.131597</td>\n",
       "      <td>2.137900</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D\n",
       "2016-01-01  0.000000  0.000000  0.159702  5\n",
       "2016-01-02  0.135802  0.709600  0.454558  5\n",
       "2016-01-03  0.700066  1.060917 -0.947943  5\n",
       "2016-01-04  0.454405 -0.783037 -0.763682  5\n",
       "2016-01-05  0.033045  0.046616  1.319882  5\n",
       "2016-01-06 -0.613064 -0.131597  2.137900  5"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['E']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.159702</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>-0.135802</td>\n",
       "      <td>-0.709600</td>\n",
       "      <td>-0.454558</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>-0.700066</td>\n",
       "      <td>-1.060917</td>\n",
       "      <td>-0.947943</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>-0.454405</td>\n",
       "      <td>-0.783037</td>\n",
       "      <td>-0.763682</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>-0.033045</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-1.319882</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.613064</td>\n",
       "      <td>-0.131597</td>\n",
       "      <td>-2.137900</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C  D\n",
       "2016-01-01  0.000000  0.000000 -0.159702 -5\n",
       "2016-01-02 -0.135802 -0.709600 -0.454558 -5\n",
       "2016-01-03 -0.700066 -1.060917 -0.947943 -5\n",
       "2016-01-04 -0.454405 -0.783037 -0.763682 -5\n",
       "2016-01-05 -0.033045 -0.046616 -1.319882 -5\n",
       "2016-01-06 -0.613064 -0.131597 -2.137900 -5"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where operation with setting!\n",
    "df[df > 0] = -df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "Or data cleansing!\n",
    "\n",
    "Let's use some real data from Wikipedia!\n",
    "\n",
    "Pandas takes a \"batteries included approach\" and throws in a whole lot of convenience functions.  For instance it has import functions for a variety of formats.  One of the pleasant surprises is a command `read_html` that's meant to automate the process of extacting tabular data from HTML.  In particular, it works pretty well with tables on Wikipedia.  \n",
    "\n",
    "Let's do an example: We'll try to extract the list of the world's tallest buildings from\n",
    "http://en.wikipedia.org/wiki/List_of_tallest_buildings_and_structures_in_the_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = pd.read_html('http://en.wikipedia.org/wiki/List_of_tallest_buildings_and_structures_in_the_world', header=0, parse_dates=False)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are several tables on the page.  By inspection we can figure out which one we want\n",
    "tallest = dfs[2]  \n",
    "tallest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates column needs to be fixed up. This needs a bit of string parsing (which you may be unfamiliar, but that's alright if you don't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_lat_long(s):\n",
    "    try:\n",
    "        parts = s.split(\"/\")\n",
    "    except AttributeError:\n",
    "        return (None, None)\n",
    "    if len(parts)<3:\n",
    "        return None\n",
    "    m=re.search(r\"(\\d+[.]\\d+);[^\\d]*(\\d+[.]\\d+)[^\\d]\", parts[2])\n",
    "    if not m:\n",
    "        return (None, None)\n",
    "    return (m.group(1), m.group(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's make some new columns\n",
    "tallest['Clean_Coordinates'] = tallest['Coordinates'].apply(clean_lat_long)\n",
    "tallest['Latitude'] = tallest['Clean_Coordinates'].apply(lambda x:x[0])\n",
    "tallest['Longitude'] = tallest['Clean_Coordinates'].apply(lambda x:x[1])\n",
    "\n",
    "# and voila...!\n",
    "tallest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Additional work: Check whether the data matches up with the one online and \n",
    "# correct the mistakes, if there are! Look out for the links in Year and Height\n",
    "# metres!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "When you read in a CSV file / SQL data base there is often \"NA\" (or \"null\", \"None\", etc.) values.  The CSV reader has a special field for specifying how this is denoted, and SQL has the built-in notion of NULL.  Pandas provides some tools for working with these.\n",
    "\n",
    "Note that these methods are by default not in place -- that is, they create a new series and do not change the original one.\n",
    "\n",
    "We're going to use a real data set, but only one column of it.  \n",
    "\n",
    "For more details: http://pandas.pydata.org/pandas-docs/stable/missing_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = {'first_name': ['Jason', np.nan, 'Tina', 'Jake', 'Amy'],\n",
    "        'last_name': ['Miller', np.nan, 'Ali', 'Milner', 'Cooze'],\n",
    "        'age': [42, np.nan, 36, 24, 73],\n",
    "        'sex': ['m', np.nan, 'f', 'm', 'f'],\n",
    "        'preTestScore': [4, np.nan, np.nan, 2, 3],\n",
    "        'postTestScore': [25, np.nan, np.nan, 62, 70]}\n",
    "df = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'sex', 'preTestScore', 'postTestScore'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop missing observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_missing = df.dropna()\n",
    "df_no_missing\n",
    "#cleaned....but a bit strict.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows where all cells in that row is NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna(how='all')\n",
    "df_cleaned\n",
    "# this may be better, some rows still might have information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column full of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['location'] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop column if they only contain missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=1, how='all')\n",
    "# location column is now gone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows that contain less than five observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(thresh=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing data with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing in preTestScore with the mean value of preTestScore\n",
    "\n",
    "`inplace=True` means that the changes are saved to `df` right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"preTestScore\"].fillna(df[\"preTestScore\"].mean(), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing in postTestScore with each sex's mean value of postTestScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"postTestScore\"].fillna(df.groupby(\"sex\")[\"postTestScore\"].transform(\"mean\"), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select some raws but ignore the missing data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the rows of df where age is not NaN and sex is not NaN\n",
    "df[df['age'].notnull() & df['sex'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Data\n",
    "\n",
    "The rest of this worksheet will use a single example, which contains data for customer counts per date at different store locations each week.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to generate test data\n",
    "def CreateDataSet(Number=1):\n",
    "    Output = []\n",
    "    for i in range(Number):\n",
    "        # Create a weekly (mondays) date range\n",
    "        rng = pd.date_range(start='1/1/2013', end='12/31/2016', freq='W-MON')\n",
    "        \n",
    "        # Create random data\n",
    "        data = np.random.randint(low=25,high=1000,size=len(rng))\n",
    "        \n",
    "        # Status pool\n",
    "        status = [1,2,3]\n",
    "        \n",
    "        # Make a random list of statuses\n",
    "        random_status = [status[np.random.randint(low=0,high=len(status))] for i in range(len(rng))]\n",
    "        \n",
    "        # State pool\n",
    "        location = ['Bangsar','Ampang','Petaling Jaya','Cheras']\n",
    "        \n",
    "        # Make a random list of states \n",
    "        random_location = [location[np.random.randint(low=0,high=len(location))] for i in range(len(rng))]\n",
    "\n",
    "        Output.extend(list(zip(random_location, random_status, data, rng)))\n",
    "        \n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = CreateDataSet(4)\n",
    "df = pd.DataFrame(data=dataset, columns=['location','Status','CustomerCount','StatusDate'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to save this dataframe into an Excel file, to then bring it back to a dataframe. We simply do this to practice reading and writing to Excel files.  \n",
    "\n",
    "We do not write the index values of the dataframe to the Excel file, since they are not meant to be part of our initial test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save results to Excel\n",
    "df.to_excel('Customers.xlsx', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of file\n",
    "Location = r'Customers.xlsx'\n",
    "\n",
    "# Parse a specific sheet - look what we did here!\n",
    "df = pd.read_excel(Location, 0, index_col='StatusDate')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return the index of df\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's pretend that status == only includes the people who \n",
    "# bought something. \n",
    "mask = df['Status'] == 1\n",
    "df = df[mask]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we may want to graph the data to check for any outliers or inconsistencies in the data. We will be using the ***plot()*** attribute of the dataframe.  \n",
    "\n",
    "As you can see from the graph below it is not very conclusive and is probably a sign that we need to perform some more data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['CustomerCount'].plot(figsize=(15,5))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the data, we begin to realize that there are multiple values for the same location, StatusDate, and Status combination. It is possible that this means the data you are working with is dirty/bad/inaccurate, but we will assume otherwise. We can assume this data set is a subset of a bigger data set and if we simply add the values in the ***CustomerCount*** column per location, StatusDate, and Status we will get the ***Total Customer Count*** per day.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortdf = df[df['location']=='Bangsar'].sort_index(axis=0)\n",
    "sortdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby\n",
    "Our task is now to create a new dataframe that compresses the data so we have daily customer counts per location and StatusDate. We can ignore the Status column since all the values in this column are of value *1*. To accomplish this we will use the dataframe's functions ***groupby*** and ***sum()***.  \n",
    "\n",
    "Note that we are using **reset_index** . If we did not, we would not have been able to group by both the location and the StatusDate since the groupby function expects only columns as inputs. The **reset_index** function will bring the index ***StatusDate*** back to a column in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group by State and StatusDate\n",
    "Daily = df.reset_index().groupby(['location','StatusDate']).sum()\n",
    "Daily.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***location*** and ***StatusDate*** columns are automatically placed in the index of the ***Daily*** dataframe. You can think of the ***index*** as the primary key of a database table but without the constraint of having unique values. Columns in the index as you will see allow us to easily select, plot, and perform calculations on the data.  \n",
    "\n",
    "Below we delete the ***Status*** column since it is all equal to one and no longer necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del Daily['Status']\n",
    "Daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try another groupby!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the index of the Daily dataframe\n",
    "Daily.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the location index\n",
    "Daily.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try unstacking with 0 and 1.\n",
    "Daily.unstack(0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tables\n",
    "\n",
    "\n",
    "Are easy! and are akin to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's Create the data set again.\n",
    "dataset = CreateDataSet(4)\n",
    "df = pd.DataFrame(data=dataset, columns=['location','Status','CustomerCount','StatusDate'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values = 'CustomerCount', \n",
    "               index = ['StatusDate','Status'],\n",
    "               columns = ['location']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values = 'CustomerCount', \n",
    "               index = ['StatusDate','location'],\n",
    "               columns = ['Status']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now plot the data per location.  \n",
    "\n",
    "As you can see by breaking the graph up by the ***location*** column we have a much clearer picture on how the data looks like. Can you spot any outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for place in Daily.index.levels[0]:\n",
    "    print(place)\n",
    "    Daily.loc[place].plot()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume that per month the customer count should remain relatively steady. Any data outside a specific range in that month will be removed from the data set. The final result should have smooth graphs with no spikes.  \n",
    "\n",
    "***LocationYearMonth*** - Here we group by location, Year of StatusDate, and Month of StatusDate.  \n",
    "***Daily['Outlier']*** - A boolean (True or False) value letting us know if the value in the CustomerCount column is ouside the acceptable range.  \n",
    "\n",
    "We will be using the attribute ***transform*** instead of ***apply***. The reason is that transform will keep the shape(# of rows and columns) of the dataframe the same and apply will not. By looking at the previous graphs, we can realize they are not resembling a gaussian distribution, this means we cannot use summary statistics like the mean and stDev. We use percentiles instead. Note that we run the risk of eliminating good data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Outliers\n",
    "LocationYearMonth = Daily.groupby([Daily.index.get_level_values(0), Daily.index.get_level_values(1).year, Daily.index.get_level_values(1).month])\n",
    "Daily['Lower'] = LocationYearMonth['CustomerCount'].transform( lambda x: x.quantile(q=.25) - (1.5*x.quantile(q=.75)-x.quantile(q=.25)) )\n",
    "Daily['Upper'] = LocationYearMonth['CustomerCount'].transform( lambda x: x.quantile(q=.75) + (1.5*x.quantile(q=.75)-x.quantile(q=.25)) )\n",
    "Daily['Outlier'] = (Daily['CustomerCount'] < Daily['Lower']) | (Daily['CustomerCount'] > Daily['Upper']) \n",
    "\n",
    "# Remove Outliers\n",
    "Daily = Daily[Daily['Outlier'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe named ***Daily*** will hold customer counts that have been aggregated per day. The original data (df) has multiple records per day.  We are left with a data set that is indexed by both the state and the StatusDate. The Outlier column should be equal to ***False*** signifying that the record is not an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We create a separate dataframe named ***ALL*** which groups the Daily dataframe by StatusDate. We are essentially getting rid of the ***Location*** column. The ***Max*** column represents the maximum customer count per month. The ***Max*** column is used to smooth out the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all markets\n",
    "\n",
    "# Get the max customer count by Date\n",
    "ALL = pd.DataFrame(Daily['CustomerCount'].groupby(Daily.index.get_level_values(1)).sum())\n",
    "ALL.columns = ['CustomerCount'] # rename column\n",
    "\n",
    "# Group by Year and Month\n",
    "YearMonth = ALL.groupby([lambda x: x.year, lambda x: x.month])\n",
    "\n",
    "# What is the max customer count per Year and Month\n",
    "ALL['Max'] = YearMonth['CustomerCount'].transform(lambda x: x.max())\n",
    "ALL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the ***ALL*** dataframe above, in the month of Jan 2013, the maximum customer count was 1702. If we had used ***apply***, we would have got a dataframe with (Year and Month) as the index and just the *Max* column with the value of 1702. \n",
    "\n",
    "\n",
    "----------------------------------  \n",
    "There is also an interest to gauge if the current customer counts were reaching certain goals the company had established. The task here is to visually show if the current customer counts are meeting the goals listed below. We will call the goals ***BHAG*** (Big Hairy Annual Goal).  \n",
    "\n",
    "* 12/31/2015 - 1,000 customers  \n",
    "* 12/31/2016 - 2,000 customers  \n",
    "* 12/31/2017 - 3,000 customers  \n",
    "\n",
    "We will be using the **date_range** function to create our dates.  \n",
    "\n",
    "***Definition:*** date_range(start=None, end=None, periods=None, freq='D', tz=None, normalize=False, name=None, closed=None)  \n",
    "***Docstring:*** Return a fixed frequency datetime index, with day (calendar) as the default frequency  \n",
    "\n",
    "By choosing the frequency to be ***A*** or annual we will be able to get the three target dates from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.date_range?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presenting Data  \n",
    "\n",
    "Create individual Graphs for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# First Graph\n",
    "ALL['Max'].plot(figsize=(10, 5));plt.title('ALL Markets')\n",
    "\n",
    "# Last four Graphs\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\n",
    "fig.subplots_adjust(hspace=1.0) ## Create space between plots\n",
    "\n",
    "Daily.loc['Bangsar']['CustomerCount']['2016':].fillna(method='pad').plot(ax=axes[0,0])\n",
    "Daily.loc['Petaling Jaya']['CustomerCount']['2016':].fillna(method='pad').plot(ax=axes[0,1]) \n",
    "Daily.loc['Ampang']['CustomerCount']['2016':].fillna(method='pad').plot(ax=axes[1,0]) \n",
    "Daily.loc['Cheras']['CustomerCount']['2016':].fillna(method='pad').plot(ax=axes[1,1]) \n",
    "\n",
    "\n",
    "\n",
    "# Add titles\n",
    "axes[0,0].set_title('Bangsar')\n",
    "axes[0,1].set_title('Petaling Jaya')\n",
    "axes[1,0].set_title('Ampang')\n",
    "axes[1,1].set_title('Cheras')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Pandas provides a \"batteries-included\" basic data analysis:\n",
    "  - **Loading data:** `read_csv`, `read_table`, `read_sql`, and `read_html`\n",
    "  - **Selection, filtering, and aggregation** (i.e., SQL-type operations): There's a special syntax for `SELECT`ing.  There's the `merge` method for `JOIN`ing.  There's also an easy syntax for what in SQL is a mouthful: Creating a new column whose value is computed from other column -- with the bonus that now the computations can use the full power of Python (though it might be faster if it didn't).\n",
    "  - **\"Pivot table\" style aggregation**: If you're an Excel cognosceti, you may appreciate this.\n",
    "  - **NA handling**: Like R's data frames, there is good support for transforming NA values with default values / averaging tricks / etc.\n",
    "  - **Basic statistics:** e.g. `mean`, `median`, `max`, `min`, and the convenient `describe`.\n",
    "  - **Plugging into more advanced analytics:** Okay, this isn't batteries included.  But still, it plays reasonably with `sklearn`.\n",
    "  - **Visualization:** For instance `plot` and `hist`.\n",
    "  \n",
    "Plugging into more advanced analytics\n",
    "-------\n",
    "Almost any \"advanced analytics\" tool in the Python ecosystem is going to take as input `np.array` type arrays.  You can access the underlying array of a data frame column as\n",
    "\n",
    "        df['column'].values\n",
    "        \n",
    "Many of them take `nd.array` whose underlying data can be accessed by \n",
    "\n",
    "        df.values\n",
    "        \n",
    "directly.  *Most* of the time, they will take `df['column']` and `df` without needing to look at values.\n",
    "\n",
    "This is particularly important if you want to use Pandas with the sklearn library. See this [blog post](http://www.markhneedham.com/blog/2013/11/09/python-making-scikit-learn-and-pandas-play-nice/) for an example."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
